{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b130faf",
   "metadata": {},
   "source": [
    "# Dynamics between mental states as a function of venlafaxine dosage\n",
    "\n",
    "In this notebook, we illustrate how to use the Wishart process to model the dynamic covariance between five mental states using venlafaxine dosage, an antidepressant, as an input variable. The dataset that we use here is available at https://osf.io/j4fg8/ and is described in the following paper:\n",
    "\n",
    "Kossakowski, J. J., Groot, P. C., Haslbeck, J. M., Borsboom, D., & Wichers, M. (2017). Data from ‘critical slowing down as a personalized early warning signal for depression’. Journal of Open Psychology Data, 5(1), 1-1.\n",
    "\n",
    "### Preprocessing\n",
    "The data comes from a single subject who has been diagnosed with Major Depressive Disorder and monitored his mental state over the course of 237 days by filling in a questionnaire of daily life experiences several times a day.  the subject had been using venlafaxine for 8.5 years, and this dosage is reduced gradually. We based our pre-processing on the following paper:\n",
    "\n",
    "Wichers, M., Groot, P. C., Psychosystems, E. S. M., & EWS Group. (2016). Critical slowing down as a personalized early warning signal for depression. Psychotherapy and psychosomatics, 85(2), 114-116."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175dcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "SELECTED_DEVICE = None\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = f''\n",
    "os.environ['JAX_PLATFORM_NAME'] = 'cpu'\n",
    "import jax\n",
    "import sys\n",
    "jax.config.update(\"jax_default_device\", jax.devices()[0])\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrnd\n",
    "import distrax as dx\n",
    "import jaxkern as jk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfb = tfp.bijectors\n",
    "module_path = os.path.abspath(os.path.join('../bayesianmodels/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from uicsmodels.gaussianprocesses.fullwp import FullLatentWishartModel\n",
    "from uicsmodels.gaussianprocesses.wputil import vec2tril, tril2vec, construct_wishart\n",
    "from uicsmodels.gaussianprocesses.likelihoods import AbstractLikelihood\n",
    "import time\n",
    "\n",
    "# Load and select data:\n",
    "data = pd.read_csv('/home/heshui/bayesianmodels/simulations/ESMdata.csv')\n",
    "columns_affect = ['mood_irritat', 'mood_satisfi', 'mood_lonely', 'mood_anxious', 'mood_enthus', \n",
    "                  'mood_cheerf', 'mood_guilty', 'mood_doubt', 'mood_strong', 'pat_restl', 'pat_agitate']\n",
    "data_subset = data[['concentrat'] + columns_affect + ['pat_worry', 'mood_suspic']].dropna()\n",
    "x = np.array(data_subset['concentrat'])\n",
    "\n",
    "# A few variables have Likert scales from -3 to 3, so we make sure all Likert scales have the same range:\n",
    "other_likert_scale = ['mood_lonely', 'mood_anxious', 'mood_guilty']\n",
    "data_subset[other_likert_scale] += 4\n",
    "\n",
    "# Apply PCA with oblique rotation:\n",
    "fa = FactorAnalyzer(method='principal', rotation='promax')\n",
    "fa.fit(data_subset[columns_affect].to_numpy())\n",
    "Y_pca = fa.transform(data_subset[columns_affect].to_numpy())\n",
    "Y = np.concatenate((Y_pca, data_subset[['pat_worry', 'mood_suspic']].to_numpy()), axis=1) # Append suspicious and worrying.\n",
    "\n",
    "# Remove slow non-linear time trends:\n",
    "pf = PolynomialFeatures(degree=5)\n",
    "xp = pf.fit_transform(np.tile(x, (Y.shape[1], 1)).T)\n",
    "md2 = LinearRegression()\n",
    "md2.fit(xp, Y)\n",
    "trend = md2.predict(xp)\n",
    "Y = Y - trend\n",
    "\n",
    "# Scale day numbers to range [0, 1]:\n",
    "minx = np.min(x)\n",
    "maxx = np.max(x)\n",
    "x = (x - minx) / (maxx - minx)\n",
    "\n",
    "# We want to use only 25% of the data, to select a subset of the data: \n",
    "idx = np.arange(0, Y.shape[0], 4)\n",
    "Y = Y[idx, :]\n",
    "x = x[idx]\n",
    "x = np.reshape(x, (-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf680e46",
   "metadata": {},
   "source": [
    "### Define likelihood with EMA mean\n",
    "We assume $Y_i \\sim \\mathcal{MVN}_d \\left( \\mu_i, \\Sigma_i \\right)$ with $\\mu_i$ being an exponential moving average function: $\\text{EMA}(y_{i+1, j}) = \\alpha [y_{ij} + (1 - \\alpha)y_{i-1, j} + (1 - \\alpha)^2 y_{i-2,j} + \\ldots + (1 - \\alpha)^{k-1}y_{i-(k-1),j}] $ and $k=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mean function (this is mu_i for Y_i ~ MVN(mu_i, Sigma_i)):\n",
    "def ema(Y, k=10):\n",
    "    \"\"\" This function implements an exponential moving average mean function.  \n",
    "\n",
    "    Args:\n",
    "        Y: a matrix with observations of shape (number of observations, number of variables).\n",
    "        k: an integer representing the number of previous observations to take into account for computing the EMA (optional).\n",
    "\n",
    "    Returns:\n",
    "        A matrix of shape (number of observations, number of variables) with the moving average.\n",
    "    \"\"\"\n",
    "    alpha = 2 / (k + 1)\n",
    "    n = Y.shape[0]\n",
    "    exponents = jnp.power(1 - alpha, jnp.arange(k))\n",
    "    moving_average = jax.vmap(lambda y_d: alpha * jnp.convolve(y_d, exponents)[:n], in_axes=(1, ))(Y)\n",
    "    moving_average = moving_average.T\n",
    "    return moving_average\n",
    "\n",
    "\n",
    "class Wishart_with_EMA(AbstractLikelihood):\n",
    "\n",
    "    def __init__(self, nu, d, Y, k=10):\n",
    "        self.nu = nu\n",
    "        self.d = d\n",
    "        self.mean = ema(Y, k=k)\n",
    "\n",
    "    def link_function(self, f):\n",
    "        \"\"\"Identity function\n",
    "        \"\"\"\n",
    "        return f\n",
    "\n",
    "    def likelihood(self, params, f=None, Sigma=None, mean=None):\n",
    "        assert f is not None or Sigma is not None, 'Provide either f or Sigma'\n",
    "        if Sigma is None:\n",
    "            if jnp.ndim(f):\n",
    "                f = jnp.reshape(f, (-1, self.nu, self.d))\n",
    "            L_vec = params['L_vec']\n",
    "            L = vec2tril(L_vec, self.d)\n",
    "            Sigma = construct_wishart(F=f, L=L)\n",
    "        mean = self.mean if mean is None else mean\n",
    "        return dx.MultivariateNormalFullCovariance(loc=mean, covariance_matrix=Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0fe0ea",
   "metadata": {},
   "source": [
    "### Modelling of dynamic covariance between mental states using the Wishart process with SMC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befb6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model settings:\n",
    "gpkernel = jk.RBF() + jk.Matern12()\n",
    "num_particles = 1000\n",
    "num_mcmc_steps = 5000\n",
    "\n",
    "# Set priors and initialize model:\n",
    "n, d = Y.shape\n",
    "len_l = int(d * (d+1) / 2)\n",
    "priors = dict(kernel = [dict(lengthscale=dx.Transformed(dx.Normal(loc=0., scale=1.), tfb.Exp())),\n",
    "                        dict(lengthscale=dx.Transformed(dx.Normal(loc=0., scale=1.), tfb.Exp()))],\n",
    "              likelihood = dict(L_vec=dx.Normal(loc=jnp.zeros((len_l, )), scale=jnp.ones((len_l, )))))\n",
    "model = FullLatentWishartModel(x, Y, cov_fn=gpkernel, priors=priors)\n",
    "model.likelihood = Wishart_with_EMA(d+1, d, Y)\n",
    "\n",
    "# Inference with SMC:\n",
    "start = time.time()\n",
    "key = jrnd.PRNGKey(10)\n",
    "particles, num_iter, lml = model.inference(key, mode='gibbs-in-smc', \n",
    "                                            sampling_parameters=dict(num_particles=num_particles, \n",
    "                                                                    num_mcmc_steps=num_mcmc_steps))\n",
    "end = time.time()\n",
    "\n",
    "# Construct covariance process over full range:\n",
    "key = jrnd.PRNGKey(5)\n",
    "x_pred = np.linspace(np.min(x), np.max(x), 100)\n",
    "Sigma_pred = model.predict_Sigma(key, x_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
